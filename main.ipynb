{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/e-caste/aiml-project/blob/master/AIML_project_with_more_batches.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "No8O0ihT7cI-"
   },
   "source": [
    "# **User Intention Prediction via Finetuned Transformer Models** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2dPKcrIl7vo-"
   },
   "source": [
    "Run the following cell to automatically create the needed directories in your Google Drive (if you're using Google Colab) or locally, depending on where your notebook is running at the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nsE5EQZg12KQ",
    "outputId": "a2d84ba4-16cd-4e3c-a06e-535c8083a9ea"
   },
   "outputs": [],
   "source": [
    "is_in_colab = 'google.colab' in str(get_ipython())\n",
    "\n",
    "if is_in_colab:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    ! [[ -d /content/drive/MyDrive ]] && echo \"Your Google Drive is mounted\" || echo \"Please try re-running this cell\"; \\\n",
    "    PROJECT_DIR=drive/MyDrive/aiml-project; \\\n",
    "    \\\n",
    "    [[ ! -d $PROJECT_DIR ]] && mkdir $PROJECT_DIR && echo \"Created directory in your Google Drive ($PROJECT_DIR in the left panel)\" || \"$PROJECT_DIR already exists\"; \\\n",
    "    [[ ! -d $PROJECT_DIR/RESULTS ]] && mkdir $PROJECT_DIR/RESULTS && mkdir $PROJECT_DIR/MODELS && echo \"Created RESULTS and MODELS directories\" || echo \"RESULTS and MODELS directories already exist, skipping creation\"; \\\n",
    "    [[ ! -d $PROJECT_DIR/data ]] && mkdir -p $PROJECT_DIR/data/simmc_fashion && echo -n \"Created data directory\" || echo -n \"Data directory already exists, skipping creation\"; \\\n",
    "    echo \", please upload the dataset into $PROJECT_DIR/data/simmc_fashion\"; \\\n",
    "    echo; echo \"Installing transformers Python library:\"; echo; pip install transformers\n",
    "else:\n",
    "    import os\n",
    "    if os.path.isdir(\"MODELS\") and os.path.isdir(\"RESULTS\"):\n",
    "        print(\"RESULTS and MODELS directories already exist, skipping creation\")\n",
    "    else:\n",
    "        if not os.path.isdir(\"RESULTS\"):\n",
    "            os.mkdir(\"RESULTS\")\n",
    "            print(\"Created RESULTS directory\")\n",
    "        if not os.path.isdir(\"MODELS\"):\n",
    "            os.mkdir(\"MODELS\")\n",
    "            print(\"Created MODELS directory\")\n",
    "    if not os.path.isdir(\"data\"):\n",
    "        os.mkdir(\"data\")\n",
    "        os.mkdir(\"data/simmc_fashion\")\n",
    "        print(\"Created data directory, please load the dataset into data/simmc_fashion\")\n",
    "    else:\n",
    "        print(\"Data directory already exists, skipping creation. Check that your dataset is in data/simmc_fashion\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "myfcu7Jt3UUZ",
    "outputId": "dc9e208b-05b0-40d6-95a4-304383c25362"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "! echo; echo \"Printing assigned GPU stats: \"; echo; nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASET PREPROCESSING\n",
    "\n",
    "To feed the correct input to our model, we first need to preprocess the dataset. If you need to do so:\n",
    "1. please check that the Tokenizer imported into `tokenize_user_utterance.py` corresponds to your model (e.g. BertTokenizer for BertModel, DistilBertTokenizer for DistilBertModel, etc.)\n",
    "2. check that `NUM_ATTRIBUTES` is set to the correct value in `enums/Attribute.py` (i.e. if `DISCARD_ATTRIBUTES_BELOW_COUNT` is set to 0 it should be 33, if `DABC` is 40 it should be 18, if `DABC` is 70 it should be 14)\n",
    "3. check that `CONT` in `preprocess_dataset.sh` loops over your desired value(s) for the model's `HISTORY` parameter\n",
    "4. then _uncomment the following cell_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# ! ./preprocess_dataset.sh || return 0  # for some reason Jupyter thinks that Bash is returning 1, suppress the warning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xf4E2MBcHsrH"
   },
   "source": [
    "# IMPORTS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uEkDIvkJHsy_"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "from enum import Enum\n",
    "import math\n",
    "import torch\n",
    "import os\n",
    "import transformers\n",
    "from transformers import AdamW\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel, BertConfig\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ttharVoaI49n"
   },
   "source": [
    "# NAME FILES FOR ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "trQqaIV0I5-e"
   },
   "outputs": [],
   "source": [
    "PROJECT_DIR = \"/content/drive/MyDrive/aiml-project/\" if is_in_colab else \"\"\n",
    "DATA_DIR = f\"{PROJECT_DIR}data/simmc_fashion/\"\n",
    "\n",
    "TRAIN_FILE = f\"{DATA_DIR}fashion_train_dials_clean_info.json\"\n",
    "TEST_FILE = f\"{DATA_DIR}fashion_devtest_dials_clean_info.json\"\n",
    "DEV_FILE = f\"{DATA_DIR}fashion_dev_dials_clean_info.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PUhoc6El5El4"
   },
   "source": [
    "## ACTION ENUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DR8BCZfjMnQY"
   },
   "outputs": [],
   "source": [
    "NUM_ACTIONS = 5\n",
    "\n",
    "class Action(Enum):\n",
    "    SpecifyInfo = 0\n",
    "    SearchDatabase = 1\n",
    "    AddToCart = 2\n",
    "    SearchMemory = 3\n",
    "    Nothing = 4\n",
    "\n",
    "    @classmethod\n",
    "    def length(cls):\n",
    "        return NUM_ACTIONS\n",
    "\n",
    "    @classmethod\n",
    "    def from_str(cls, action):\n",
    "        if action == \"SearchDatabase\":\n",
    "            return cls.SearchDatabase.value\n",
    "        elif action == \"SpecifyInfo\":\n",
    "            return cls.SpecifyInfo.value\n",
    "        elif action == \"AddToCart\":\n",
    "            return cls.AddToCart.value\n",
    "        elif action == \"SearchMemory\":\n",
    "            return cls.SearchMemory.value\n",
    "        else:\n",
    "            return cls.Nothing.value\n",
    "\n",
    "    @classmethod\n",
    "    def from_number(cls, value):\n",
    "        if value == cls.SpecifyInfo.value:\n",
    "            return \"SpecifyInfo\"\n",
    "        elif value == cls.SearchDatabase.value:\n",
    "            return \"SearchDatabase\"\n",
    "        elif value == cls.AddToCart.value:\n",
    "            return \"AddToCart\"\n",
    "        elif value == cls.SearchMemory.value:\n",
    "            return \"SearchMemory\"\n",
    "        else:\n",
    "            return \"None\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xsm_3W0VHs9Q"
   },
   "source": [
    "# DATASET ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "XUz0kb_aHtFH",
    "outputId": "0ab6e4f5-8821-4dc8-c379-a8355a8bb269"
   },
   "outputs": [],
   "source": [
    "files = [TRAIN_FILE, TEST_FILE, DEV_FILE]\n",
    "for file in files:\n",
    "    print(f\"Analyse {file} file\")\n",
    "    with open(file, \"r\") as file_id:\n",
    "        dials_clean = json.load(file_id)\n",
    "\n",
    "    actions = []\n",
    "    actions_counts = []\n",
    "    actions_num = []\n",
    "    attributes = []\n",
    "    attributes_counts = []\n",
    "    count_turns = []\n",
    "\n",
    "    MAX_TURNS = 13\n",
    "    for i in range(MAX_TURNS):\n",
    "        count_turns.append(0)\n",
    "        for dial in dials_clean:\n",
    "            if len(dial) == i + 1:\n",
    "                count_turns[i] += 1\n",
    "\n",
    "    for dial in dials_clean:\n",
    "        for turn in dial:\n",
    "            if turn[\"action\"] not in actions:\n",
    "                actions.append(turn[\"action\"])\n",
    "                actions_counts.append(1)\n",
    "                actions_num.append(Action.from_str(turn[\"action\"]))\n",
    "            else:\n",
    "                actions_counts[actions.index(turn[\"action\"])] += 1\n",
    "\n",
    "            for attr in turn[\"attributes\"]:\n",
    "                if attr not in attributes:\n",
    "                    attributes.append(attr)\n",
    "                    attributes_counts.append(1)\n",
    "                else:\n",
    "                    attributes_counts[attributes.index(attr)] += 1\n",
    "\n",
    "    actions_num, weight_action = (list(tup) for tup in zip(*sorted(zip(actions_num, actions_counts))))\n",
    "                    \n",
    "    #count distribution of actions for each attribute\n",
    "    attrs_voc = []\n",
    "    for i in range(len(attributes)):\n",
    "        attrs_voc.append({\"name\": attributes[i],\n",
    "                          \"SearchDatabase\": 0,\n",
    "                          \"SpecifyInfo\": 0,\n",
    "                          \"AddToCart\": 0,\n",
    "                          \"SearchMemory\": 0,\n",
    "                          \"None\": 0\n",
    "                          })\n",
    "        \n",
    "\n",
    "    for i in range(len(attributes)):\n",
    "        for dial in dials_clean:\n",
    "            for turn in dial:\n",
    "                if attributes[i] in turn[\"attributes\"]:\n",
    "                    attrs_voc[i][turn[\"action\"]] += 1\n",
    "\n",
    "    attrs_voc = sorted(attrs_voc, key=lambda d: d[\"SearchDatabase\"] + d[\"SpecifyInfo\"] + d[\"AddToCart\"] + d[\"SearchMemory\"] + d[\"None\"])\n",
    "    # sort actions by descending frequency\n",
    "    actions_counts, actions = (list(tup) for tup in zip(*sorted(zip(actions_counts, actions))))\n",
    "    \n",
    "    # sort attributes by descending frequency\n",
    "    attributes_counts, attributes  = (list(tup) for tup in zip(*sorted(zip(attributes_counts, attributes))))\n",
    "    \n",
    "    # list of tuples [(attribute, frequency), ...]\n",
    "    if file == TRAIN_FILE:\n",
    "        attr_attr_counts = sorted(zip(attributes_counts, attributes), reverse=True)\n",
    "        count = 70\n",
    "        print(attr_attr_counts, len(attr_attr_counts))\n",
    "        attr_filtered = list(filter(lambda elem: elem[0] < count, attr_attr_counts))\n",
    "        print(f\"Attributes with count < {count}: {attr_filtered} with length {len(attr_filtered)}\")\n",
    "\n",
    "    # barplot for dial length distribution\n",
    "    y_act_pos = np.arange(len(count_turns))\n",
    "    plt.figure(dpi=300, tight_layout=True)\n",
    "    plt.barh(y_act_pos, count_turns)\n",
    "    plt.yticks(y_act_pos, range(1,MAX_TURNS+1))\n",
    "    plt.grid(alpha=0.2)\n",
    "    plt.ylabel('Dialog turn count')\n",
    "    plt.xlabel('Number of occurrences')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # barplot for actions\n",
    "    y_act_pos = np.arange(len(actions))\n",
    "    plt.figure(dpi=300, tight_layout=True)\n",
    "    plt.barh(y_act_pos, actions_counts)\n",
    "    plt.yticks(y_act_pos, actions)\n",
    "    plt.grid(alpha=0.2)\n",
    "    plt.ylabel('Action label')\n",
    "    plt.xlabel('Number of occurrences')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # barplot for attributes\n",
    "    y_attr_pos = np.arange(len(attributes))\n",
    "    plt.figure(dpi=300, tight_layout=True, figsize=(10,6))\n",
    "    plt.barh(y_attr_pos, attributes_counts)\n",
    "    plt.yticks(y_attr_pos, attributes)\n",
    "    plt.grid(alpha=0.2)\n",
    "    plt.ylabel('Attribute label')\n",
    "    plt.xlabel('Number of occurrences')\n",
    "    plt.semilogx()\n",
    "    plt.show()\n",
    "\n",
    "    # barplot for actions distribution for each attributes\n",
    "    a0 = []\n",
    "    a1 = []\n",
    "    a2 = []\n",
    "    a3 = []\n",
    "    a4 = []\n",
    "\n",
    "    for i in range(len(attributes)):\n",
    "        a0.append(attrs_voc[i][\"SearchDatabase\"])\n",
    "        a1.append(attrs_voc[i][\"SpecifyInfo\"])\n",
    "        a2.append(attrs_voc[i][\"AddToCart\"])\n",
    "        a3.append(attrs_voc[i][\"SearchMemory\"])\n",
    "        a4.append(attrs_voc[i][\"None\"])\n",
    "        \n",
    "    sum1 = np.add(a0, a1).tolist()\n",
    "    sum2 = np.add(sum1, a2).tolist()\n",
    "    sum3 = np.add(sum2, a3).tolist()\n",
    "    \n",
    "    plt.figure(dpi=300, tight_layout=True, figsize=(10,6))\n",
    "    plt.barh(y_attr_pos, a0, color='blue', edgecolor='black', label='SearchDatabase')\n",
    "    plt.barh(y_attr_pos, a1, left=a0, color='red', edgecolor='black', label='SpecifyInfo')\n",
    "    plt.barh(y_attr_pos, a2, left=sum1, color='yellow', edgecolor='black', label='AddToCart')\n",
    "    plt.barh(y_attr_pos, a3, left=sum2, color='green', edgecolor='black', label='SearchMemory')\n",
    "    plt.barh(y_attr_pos, a4, left=sum3, color='orange', edgecolor='black', label='None')\n",
    "    plt.yticks(y_attr_pos, attributes)\n",
    "    plt.ylabel('Attribute label')\n",
    "    plt.xlabel('Number of occurrences')\n",
    "    plt.grid(alpha=0.2)\n",
    "    plt.semilogx()\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NT-xLfpJyw4k"
   },
   "source": [
    "## SET HYPERPARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J564lSFFLHv9"
   },
   "outputs": [],
   "source": [
    "LEARNING_RATE = 9e-7\n",
    "DISCARD_ATTRIBUTES_BELOW_COUNT = 70  # you should re-run the pre-process script if you modify this\n",
    "FEATURES = 768  # 768 for bert-base-uncased and 1024 for bert-large-uncased\n",
    "ACTION_DROPOUT = .3\n",
    "ATTRIBUTES_DROPOUT = .1\n",
    "MAX_EPOCHS = 13\n",
    "TRAIN_BATCH_SIZE = 4\n",
    "TEST_BATCH_SIZE = 4\n",
    "HISTORY = 6  # number of preceding utterances to consider\n",
    "\n",
    "HISTORY_PAD = f\"_history{HISTORY}\" if HISTORY else \"\"\n",
    "TRAIN_FILE = f\"{DATA_DIR}fashion_train_dials_info_tokenized{HISTORY_PAD}.json\"\n",
    "TEST_FILE = f\"{DATA_DIR}fashion_devtest_dials_info_tokenized{HISTORY_PAD}.json\"\n",
    "DEV_FILE = f\"{DATA_DIR}fashion_dev_dials_info_tokenized{HISTORY_PAD}.json\"\n",
    "DEMO_FILE = f\"{DATA_DIR}train_demo_small.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "96mZBesoMjI8"
   },
   "source": [
    "# CREATE DATALOADER AND ENUMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eA6zYvc549Cw"
   },
   "source": [
    "## DATALOADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yDmXTt0-Mmog"
   },
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, file_dials):\n",
    "        \"\"\"Constructor of class\n",
    "           Args:\n",
    "                file_dials: path of file_dials\n",
    "        \"\"\"\n",
    "        super(Dataset, self).__init__()\n",
    "\n",
    "        # create a vectors of dials with turns\n",
    "        with open(file_dials, \"r\") as file_id:\n",
    "            self.dials = json.load(file_id)\n",
    "\n",
    "        # create a vector of single turn (without considering the dial)\n",
    "        self.turns = []\n",
    "        self.phrases = {\n",
    "            \"dialog_id\":[],\n",
    "            \"turn_idx\":[],\n",
    "            \"input_ids\": [],\n",
    "            \"attention_mask\": []\n",
    "        }\n",
    "        self.labels = {\n",
    "           \"action\": [],\n",
    "           \"attributes\": []\n",
    "        }\n",
    "        for dial in self.dials:\n",
    "            for turn in dial:\n",
    "                self.turns.append(turn)\n",
    "\n",
    "        for turn in self.turns:\n",
    "            self.phrases[\"input_ids\"].append(turn[\"user_utterance\"][\"input_ids\"])\n",
    "            self.phrases[\"attention_mask\"].append(turn[\"user_utterance\"][\"attention_mask\"])\n",
    "            self.phrases[\"turn_idx\"].append(turn[\"turn_idx\"])\n",
    "            self.phrases[\"dialog_id\"].append(turn[\"dialog_id\"])\n",
    "            self.labels[\"action\"].append(turn[\"action\"])\n",
    "            self.labels[\"attributes\"].append(turn[\"attributes\"])\n",
    "\n",
    "        self.phrases[\"input_ids\"] = torch.tensor(self.phrases[\"input_ids\"], dtype=torch.long)\n",
    "        self.phrases[\"attention_mask\"] = torch.tensor(self.phrases[\"attention_mask\"], dtype=torch.long)\n",
    "        self.phrases[\"dialog_id\"] = torch.tensor(self.phrases[\"dialog_id\"], dtype=torch.long)\n",
    "        self.phrases[\"turn_idx\"] =  torch.tensor(self.phrases[\"turn_idx\"], dtype=torch.long)\n",
    "        self.labels[\"action\"] = torch.tensor(self.labels[\"action\"], dtype=torch.long)\n",
    "        self.labels[\"attributes\"] = torch.tensor(self.labels[\"attributes\"], dtype=torch.float)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Method to return the length of turns\n",
    "             Returns:\n",
    "                length of turns\n",
    "        \"\"\"\n",
    "        return len(self.turns)\n",
    "\n",
    "    def __getitem__(self, index_turn):\n",
    "        \"\"\"\"Method to return an phrase of dataset (without considering the dials)\n",
    "             Args:\n",
    "                 index_turn: index of turn of interest (not numbered for dialogs)\n",
    "             Returns:\n",
    "                 x: user_utterance + info turns id, dialouge_id\n",
    "                 y: label (action to predict and attributes)\n",
    "        \"\"\"\n",
    "        phrase = {\n",
    "            \"turn_idx\": self.phrases[\"turn_idx\"][index_turn],\n",
    "            \"dialog_id\": self.phrases[\"dialog_id\"][index_turn],\n",
    "            \"input_ids\": self.phrases[\"input_ids\"][index_turn],\n",
    "            \"attention_mask\": self.phrases[\"attention_mask\"][index_turn]\n",
    "        }\n",
    "        label = {\n",
    "            \"action\": self.labels[\"action\"][index_turn],\n",
    "            \"attributes\": self.labels[\"attributes\"][index_turn]\n",
    "         }\n",
    "        return phrase, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ejoJa-Fk5JYB"
   },
   "source": [
    "## ATTRIBUTE ENUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fulAVOdING_Y",
    "outputId": "9bf90124-b8e4-4178-b966-12a65ccb0bc0"
   },
   "outputs": [],
   "source": [
    "NUM_ATTRIBUTES = len(list(filter(lambda elem: elem[0] > DISCARD_ATTRIBUTES_BELOW_COUNT, attr_attr_counts))) + 1\n",
    "print(f\"Using the {NUM_ATTRIBUTES-1} most frequent attibutes.\")\n",
    "\n",
    "class Attribute(Enum):\n",
    "    other = 0\n",
    "    price = 1\n",
    "    availableSizes = 2\n",
    "    customerRating = 3\n",
    "    brand = 4\n",
    "    info = 5\n",
    "    color = 6\n",
    "    embellishment = 7\n",
    "    pattern = 8\n",
    "    hemLength = 9\n",
    "    skirtStyle = 10\n",
    "    dressStyle = 11\n",
    "    material = 12\n",
    "    clothingStyle = 13\n",
    "    necklineStyle = 14\n",
    "    size = 15\n",
    "    jacketStyle = 16\n",
    "    sweaterStyle = 17\n",
    "    hemStyle = 18\n",
    "    sleeveStyle = 19\n",
    "    waistStyle = 20\n",
    "    sleeveLength = 21\n",
    "    clothingCategory = 22\n",
    "    skirtLength = 23\n",
    "    soldBy = 24\n",
    "    madeIn = 25\n",
    "    ageRange = 26\n",
    "    waterResistance = 27\n",
    "    warmthRating = 28\n",
    "    sequential = 29\n",
    "    hasPart = 30\n",
    "    forOccasion = 31\n",
    "    forGender = 32\n",
    "    amountInStock = 33\n",
    "\n",
    "    @classmethod\n",
    "    def length(cls):\n",
    "        return NUM_ATTRIBUTES\n",
    "\n",
    "    @classmethod\n",
    "    def from_str(cls, attribute):\n",
    "        if attribute == \"price\":\n",
    "            value = cls.price.value\n",
    "        elif attribute == \"availableSizes\":\n",
    "            value = cls.availableSizes.value\n",
    "        elif attribute == \"customerRating\":\n",
    "            value = cls.customerRating.value\n",
    "        elif attribute == \"brand\":\n",
    "            value = cls.brand.value\n",
    "        elif attribute == \"info\":\n",
    "            value = cls.info.value\n",
    "        elif attribute == \"color\":\n",
    "            value = cls.color.value\n",
    "        elif attribute == \"embellishment\":\n",
    "            value = cls.embellishment.value\n",
    "        elif attribute == \"pattern\":\n",
    "            value = cls.pattern.value\n",
    "        elif attribute == \"hemLength\":\n",
    "            value = cls.hemLength.value\n",
    "        elif attribute == \"skirtStyle\":\n",
    "            value = cls.skirtStyle.value\n",
    "        elif attribute == \"dressStyle\":\n",
    "            value = cls.dressStyle.value\n",
    "        elif attribute == \"material\":\n",
    "            value = cls.material.value\n",
    "        elif attribute == \"clothingStyle\":\n",
    "            value = cls.clothingStyle.value\n",
    "        elif attribute == \"necklineStyle\":\n",
    "            value = cls.necklineStyle.value\n",
    "        elif attribute == \"size\":\n",
    "            value = cls.size.value\n",
    "        elif attribute == \"jacketStyle\":\n",
    "            value = cls.jacketStyle.value\n",
    "        elif attribute == \"sweaterStyle\":\n",
    "            value = cls.sweaterStyle.value\n",
    "        elif attribute == \"hemStyle\":\n",
    "            value = cls.hemStyle.value\n",
    "        elif attribute == \"sleeveStyle\":\n",
    "            value = cls.sleeveStyle.value\n",
    "        elif attribute == \"waistStyle\":\n",
    "            value = cls.waistStyle.value\n",
    "        elif attribute == \"sleeveLength\":\n",
    "            value = cls.sleeveLength.value\n",
    "        elif attribute == \"clothingCategory\":\n",
    "            value = cls.clothingCategory.value\n",
    "        elif attribute == \"skirtLength\":\n",
    "            value = cls.skirtLength.value\n",
    "        elif attribute == \"soldBy\":\n",
    "            value = cls.soldBy.value\n",
    "        elif attribute == \"madeIn\":\n",
    "            value = cls.madeIn.value\n",
    "        elif attribute == \"ageRange\":\n",
    "            value = cls.ageRange.value\n",
    "        elif attribute == \"waterResistance\":\n",
    "            value = cls.waterResistance.value\n",
    "        elif attribute == \"warmthRating\":\n",
    "            value = cls.warmthRating.value\n",
    "        elif attribute == \"sequential\":\n",
    "            value = cls.sequential.value\n",
    "        elif attribute == \"hasPart\":\n",
    "            value = cls.hasPart.value\n",
    "        elif attribute == \"forOccasion\":\n",
    "            value = cls.forOccasion.value\n",
    "        elif attribute == \"forGender\":\n",
    "            value = cls.forGender.value\n",
    "        elif attribute == \"amountInStock\":\n",
    "            value = cls.amountInStock.value\n",
    "        if value < NUM_ATTRIBUTES:\n",
    "            return value\n",
    "        else:\n",
    "            return cls.other.value\n",
    "            \n",
    "    @classmethod\n",
    "    def from_number(cls, value):\n",
    "        if value == cls.price.value:\n",
    "            return \"price\"\n",
    "        elif value == cls.availableSizes.value:\n",
    "            return \"availableSizes\"\n",
    "        elif value == cls.customerRating.value:\n",
    "            return \"customerRating\"\n",
    "        elif value == cls.brand.value:\n",
    "            return \"brand\"\n",
    "        elif value == cls.info.value:\n",
    "            return \"info\"\n",
    "        elif value == cls.color.value:\n",
    "            return \"color\"\n",
    "        elif value == cls.embellishment.value:\n",
    "            return \"embellishment\"\n",
    "        elif value == cls.pattern.value:\n",
    "            return \"pattern\"\n",
    "        elif value == cls.hemLength.value:\n",
    "            return \"hemLength\"\n",
    "        elif value == cls.skirtStyle.value:\n",
    "            return \"skirtStyle\"\n",
    "        elif value == cls.dressStyle.value:\n",
    "            return \"dressStyle\"\n",
    "        elif value == cls.material.value:\n",
    "            return \"material\"\n",
    "        elif value == cls.clothingStyle.value:\n",
    "            return \"clothingStyle\"\n",
    "        elif value == cls.necklineStyle.value:\n",
    "            return \"necklineStyle\"\n",
    "        elif value == cls.size.value:\n",
    "            return \"size\"\n",
    "        elif value == cls.jacketStyle.value:\n",
    "            return \"jacketStyle\"\n",
    "        elif value == cls.sweaterStyle.value:\n",
    "            return \"sweaterStyle\"\n",
    "        elif value == cls.hemStyle.value:\n",
    "            return \"hemStyle\"\n",
    "        elif value == cls.sleeveStyle.value:\n",
    "            return \"sleeveStyle\"\n",
    "        elif value == cls.waistStyle.value:\n",
    "            return \"waistStyle\"\n",
    "        elif value == cls.sleeveLength.value:\n",
    "            return \"sleeveLength\"\n",
    "        elif value == cls.clothingCategory.value:\n",
    "            return \"clothingCategory\"\n",
    "        elif value == cls.skirtLength.value:\n",
    "            return \"skirtLength\"\n",
    "        elif value == cls.soldBy.value:\n",
    "            return \"soldBy\"\n",
    "        elif value == cls.madeIn.value:\n",
    "            return \"madeIn\"\n",
    "        elif value == cls.ageRange.value:\n",
    "            return \"ageRange\"\n",
    "        elif value == cls.waterResistance.value:\n",
    "            return \"waterResistance\"\n",
    "        elif value == cls.warmthRating.value:\n",
    "            return \"warmthRating\"\n",
    "        elif value == cls.sequential.value:\n",
    "            return \"sequential\"\n",
    "        elif value == cls.hasPart.value:\n",
    "            return \"hasPart\"\n",
    "        elif value == cls.forOccasion.value:\n",
    "            return \"forOccasion\"\n",
    "        elif value == cls.forGender.value:\n",
    "            return \"forGender\"\n",
    "        elif value == cls.amountInStock.value:\n",
    "            return \"amountInStock\"\n",
    "        else:\n",
    "            return \"other\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bzpQTxsfNPsg"
   },
   "source": [
    "# CREATE MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SrOI5k-by2V9"
   },
   "source": [
    "## MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dx2rEl7nNRp4"
   },
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = use_cuda\n",
    "\n",
    "class Assistant(nn.Module):\n",
    "    def __init__(self, num_actions, num_attributes):\n",
    "        \"\"\"\n",
    "        :param num_actions: number of possible actions to be predicted\n",
    "        :param num_attributes: number of possible attributes to be predicted\n",
    "        \"\"\"\n",
    "        super(Assistant, self).__init__()\n",
    "        self.model = 'bert-base-uncased' if FEATURES == 768 else 'bert-large-uncased'\n",
    "        self.bert = BertModel.from_pretrained(self.model)\n",
    "        \n",
    "        # layer for action\n",
    "        self.action_pre_classifier = nn.Linear(FEATURES, FEATURES)\n",
    "        self.action_activation = nn.ReLU()\n",
    "        self.action_dropout = nn.Dropout(ACTION_DROPOUT)  # avoid overfitting\n",
    "        \n",
    "        self.action_classifier = nn.Linear(FEATURES, num_actions)\n",
    "\n",
    "        # layer for attributes\n",
    "        self.attributes_dropout = nn.Dropout(ATTRIBUTES_DROPOUT)  # avoid overfitting\n",
    "        self.attributes_classifier = nn.Linear(FEATURES, num_attributes)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "           \n",
    "\n",
    "    def forward(self, batch: dict, label, predict):\n",
    "        output = self.bert(input_ids=batch['input_ids'],attention_mask=batch['attention_mask'])\n",
    "        hidden_state= output[0]\n",
    "        pooler_output = hidden_state[:, 0]\n",
    "        #predict action\n",
    "        pooler_action = self.action_pre_classifier(pooler_output)\n",
    "        pooler_action = self.action_activation(pooler_action)\n",
    "        pooler_action = self.action_dropout(pooler_action)\n",
    "        action_logits = self.action_classifier(pooler_action)\n",
    "        if predict:\n",
    "            action_pred_tensor = torch.nn.functional.softmax(action_logits, dim=1)\n",
    "            _, action_pred = torch.max(action_pred_tensor.data, dim=1) \n",
    "        else:\n",
    "            action_pred = []\n",
    "\n",
    "        # Predict attributes\n",
    "        pooler_attributes = self.attributes_dropout(pooler_output)\n",
    "        attributes_logits = self.attributes_classifier(pooler_attributes)\n",
    "        # predict best predicted attrs vector\n",
    "        if predict:\n",
    "            attributes_prob = self.sigmoid(attributes_logits) # used to calculate the probability of every attributes in prediction, not as an activation function\n",
    "            attributes_pred = self.search_best_predict_attributes(label['attributes'], attributes_prob)\n",
    "        else:\n",
    "            attributes_pred = []\n",
    "        return action_logits, action_pred, attributes_logits, attributes_pred\n",
    "\n",
    "    def search_best_predict_attributes(self, true_attributes, pred_attributes_prob):\n",
    "        # Store the list of f1 scores for prediction on each threshold\n",
    "        # convert labels to 1D array\n",
    "        opt_pred_attrs = [] \n",
    "        i=0\n",
    "        for true_attr in true_attributes:\n",
    "          pred_attrs = []\n",
    "          scores = []\n",
    "          tr_attr = np.array(true_attr.cpu())\n",
    "          is_all_zero = np.all(tr_attr == 0.0)\n",
    "          if is_all_zero: #not predict attributes if label attributes is empty\n",
    "            best_attrs_choose = true_attr\n",
    "          else: #select the best attr predict using dynamic trhesold\n",
    "            pred_prob = pred_attributes_prob[i]\n",
    "            step_increment = 0.001\n",
    "            min_threshold = torch.min(pred_prob).item() \n",
    "            max_threshold = torch.max(pred_prob).item()\n",
    "            thresholds = np.arange(min_threshold-0.01, max_threshold+0.01, step_increment)\n",
    "            thresholds = thresholds[::-1] #reverse array\n",
    "            # classes for each threshold\n",
    "            for thresh in thresholds:\n",
    "                # convert probability of vector of pred_prob in multi-label output\n",
    "                pred_attr = np.where(pred_prob.cpu() > thresh, 1, 0)\n",
    "                is_all_zero_pred = np.all(pred_attr == 0) # attrs is not empty: skip this case in possible prediction\n",
    "                if not is_all_zero_pred:\n",
    "                  pred_attr = torch.tensor(pred_attr).to(device=device)\n",
    "                  pred_attrs.append(pred_attr) \n",
    "                  # save metric to search best convertion of attributes array respect the true target\n",
    "                  score = metrics.f1_score(true_attr.cpu(), pred_attr.cpu(), average='weighted')\n",
    "                  scores.append(score)\n",
    "                  if score == 1: #best score found!\n",
    "                     break\n",
    "            # select the pred_attrs with max score\n",
    "            best_attrs_choose = pred_attrs[scores.index(max(scores))]\n",
    "          opt_pred_attrs.append(best_attrs_choose)\n",
    "          i = i + 1\n",
    "        opt_pred_attrs = torch.stack(opt_pred_attrs)\n",
    "        return opt_pred_attrs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LxbDA8Dt5RxB"
   },
   "source": [
    "# TRAIN/TEST MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "scGnOlc05fOj"
   },
   "source": [
    "# TRAINING STEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 739,
     "referenced_widgets": [
      "2624feef679145caa2dd8a6add7ebbaf",
      "57e92482a66a4f6c896999e78945c715",
      "9c741453c05f4d7baff52189a8e23b9b",
      "88c826d18c1b4b148ad7f860502a0387",
      "b7d6332b2ed94d6aa4c4865df0007459",
      "a2d9ca91e34a4c91914d0b804a1c63bf",
      "af4b6754ed0f478981861fbc860af8c0",
      "2a2df1587d824a13998c6d31e949f685",
      "29ef9d781eb34502b11d666c2c5988ee",
      "6863eb04e9ff4018b4eba17c68776a6b",
      "1fb808764af44f029c1f1dce96d304f6",
      "faff48e5ef5c445aa8d793551d6594ad",
      "ceb339d318c34c69a9db64cdb1b4b4ea",
      "e9960e30c15c44a99e400fd040e4f06a",
      "dd6602d9fbf844cba23074cc26e12c4e",
      "286b546fecfc401dad698815a6ae792c",
      "0b5155bf72bb4e9b9353b537d16b8da1",
      "f1571617dfce49538fc2fb6364365bcf",
      "8896645e63b247b7916fdca9000b5fff",
      "031bf5191a61439cb0e61cff553e7baa",
      "aef37d1229c64f91a56b0dea7a1b03e8",
      "320aeb208cf74263bd6a32e82cab7b62"
     ]
    },
    "id": "8dLCszVmLFMf",
    "outputId": "286c6235-04ee-4434-f7be-f02b8f743161"
   },
   "outputs": [],
   "source": [
    "print(f\"Using device: {device}\")\n",
    "\n",
    "min_epochs = 0\n",
    "\n",
    "# checkpoints is the list of already available checkpoint numbers\n",
    "checkpoints = sorted([\n",
    "    int(fname.split(\"epoch\")[1].split(\".pth\")[0]) \n",
    "    for fname in os.listdir(f\"{PROJECT_DIR}MODELS\") if fname.endswith(\".pth\")\n",
    "])\n",
    "if checkpoints:\n",
    "    ans = input(f\"The following saved checkpoints already exist:\\n{checkpoints}\\n\" \\\n",
    "                \"Enter the number of the checkpoint to resume from, or enter to train a model from scratch: [1,2,3... | Enter]\\n\")\n",
    "    if not ans.isdigit():\n",
    "        print(\"Instantiating default pretrained model to train from scratch...\")\n",
    "        model = Assistant(Action.length(), Attribute.length())\n",
    "    else:\n",
    "        min_epochs = int(ans)\n",
    "        if min_epochs > MAX_EPOCHS:\n",
    "            print(f\"WARNING: model checkpoint to load is {ans}, but MAX_EPOCHS is set to {MAX_EPOCHS}.\\n\" \\\n",
    "                  \"Training is already finished, or some parameters are wrongly set up. Stopping...\")\n",
    "            exit(1)\n",
    "        print(f\"Loading checkpoint {ans} into model...\")\n",
    "        model = torch.load(f\"{PROJECT_DIR}MODELS/model_epoch{ans}.pth\")\n",
    "        with open(f\"{PROJECT_DIR}MODELS/losses_epoch{ans}.json\", \"r\") as f:\n",
    "            loss_act_array_tr, loss_attrs_array_tr = json.load(f)\n",
    "else:\n",
    "    print(f\"No previous checkpoints found in {PROJECT_DIR}MODELS.\\n\" \\\n",
    "          \"Instantiating default pretrained model to train from scratch...\")\n",
    "    model = Assistant(Action.length(), Attribute.length())\n",
    "    \n",
    "model.to(device)\n",
    "model.train()\n",
    "optim = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "loss_function_action = torch.nn.CrossEntropyLoss()\n",
    "# if you wish to use a weighted CrossEntropy loss, comment the line above and uncomment the line below\n",
    "# loss_function_action = torch.nn.CrossEntropyLoss(weight=weight_action)\n",
    "loss_function_attributes = torch.nn.BCEWithLogitsLoss()\n",
    "dataset = Dataset(TRAIN_FILE)\n",
    "max_epochs = MAX_EPOCHS\n",
    "params = {\n",
    "    'shuffle': True,\n",
    "    'batch_size': TRAIN_BATCH_SIZE,\n",
    "}\n",
    "dataloader = torch.utils.data.DataLoader(dataset, **params)\n",
    "print(f\"Our dataset has {len(dataset)} entries.\")\n",
    "print(f\"Training for {max_epochs - min_epochs} epochs, each with {len(dataloader)} steps.\")\n",
    "if min_epochs == 0:\n",
    "    loss_act_array_tr = []\n",
    "    loss_attrs_array_tr = []\n",
    "\n",
    "for epoch in range(min_epochs, max_epochs):\n",
    "    loss_act_tot = 0\n",
    "    loss_attrs_tot = 0\n",
    "    counter_loss = 0 #counter of number of iteration to calculate mean of losses\n",
    "    for batch, label in tqdm(dataloader, position=0, leave=True):\n",
    "        for key in batch:\n",
    "            batch[key] = batch[key].to(device, dtype=torch.long)\n",
    "        label['action'] = label['action'].to(device, dtype=torch.long)\n",
    "        label['attributes'] = label['attributes'].to(device, dtype=torch.float)\n",
    "        action_logits, action_pred, attributes_logits, attributes_pred = model(batch, label, predict=False)\n",
    "        # action, attributes  metrics loss\n",
    "        loss_action = loss_function_action(action_logits.view(-1, Action.length()), label['action'].view(-1))\n",
    "        # if you wish to use a weighted CrossEntropy loss, comment the line above and uncomment the line below\n",
    "        # loss_action = loss_function_action(action_logits, label['action'])\n",
    "        loss_act_tot += loss_action.item()\n",
    "        #\n",
    "        loss_attributes = loss_function_attributes(attributes_logits.view(-1, Attribute.length()), label['attributes'].view(-1, Attribute.length()))\n",
    "        loss_attrs_tot += loss_attributes.item()\n",
    "        loss = (loss_action + loss_attributes)/2\n",
    "        counter_loss += 1\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "    # save results\n",
    "    loss_act_array_tr.append(loss_act_tot/counter_loss) # mean of losses of action in epoch\n",
    "    loss_attrs_array_tr.append(loss_attrs_tot/counter_loss)  # mean of losses of attributes in epoch\n",
    "    print(f\"Epoch {epoch + 1}:\\nAction loss: {loss_act_tot/counter_loss} | Attributes loss: {loss_attrs_tot/counter_loss}\")\n",
    "    with open(f\"{PROJECT_DIR}MODELS/losses_epoch{epoch + 1}.json\", \"w\") as f:\n",
    "        json.dump([loss_act_array_tr, loss_attrs_array_tr], f)\n",
    "    torch.save(model, f\"{PROJECT_DIR}MODELS/model_epoch{epoch + 1}.pth\")\n",
    "\n",
    "loss_action = loss_act_array_tr[MAX_EPOCHS-1]\n",
    "print(f'Evaluate TRAIN Loss action: {loss_action}')\n",
    "#\n",
    "loss_attributes =  loss_attrs_array_tr[MAX_EPOCHS-1]\n",
    "print(f'Evaluate TRAIN Loss attributes: {loss_attributes}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "70E6MhWRiaKI"
   },
   "source": [
    "## TESTING STEP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yZohFthEifqY",
    "outputId": "c20ae826-2df2-4833-c81e-588acd080691"
   },
   "outputs": [],
   "source": [
    "SPLITS_TEST = [TEST_FILE, DEV_FILE]\n",
    "#vector of vector of value of losses for every split\n",
    "losses_act_array = []\n",
    "losses_attrs_array = []\n",
    "accs_act_array = []\n",
    "accs_attrs_array = []\n",
    "\n",
    "for file in SPLITS_TEST:\n",
    "    split = \"devtest\" if \"devtest\" in file else \"dev\"\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    loss_function_action = torch.nn.CrossEntropyLoss()\n",
    "    # if you wish to use a weighted CrossEntropy loss, comment the line above and uncomment the line below\n",
    "    # loss_function_action = torch.nn.CrossEntropyLoss(weight=weight_action)\n",
    "    loss_function_attributes = torch.nn.BCEWithLogitsLoss()\n",
    "    dataset = Dataset(file)\n",
    "    max_epochs = MAX_EPOCHS\n",
    "    params = {\n",
    "        'shuffle': True,\n",
    "        'batch_size': TEST_BATCH_SIZE,\n",
    "    }\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, **params)\n",
    "    print(f\"Evaluate Our dataset with {len(dataset)} entries.\")\n",
    "    print(f\"Evaluate for {max_epochs} epochs, each with {len(dataloader)} steps.\")\n",
    "    loss_act_array = []\n",
    "    loss_attrs_array = []\n",
    "    acc_act_array = []\n",
    "    acc_attrs_array = []\n",
    "    for epoch in range(max_epochs):\n",
    "        total_loss_action = 0\n",
    "        total_loss_attrs = 0\n",
    "        counter_loss = 0 #counter of number of iteration to calculate mean of losses\n",
    "        model = torch.load(f\"{PROJECT_DIR}MODELS/model_epoch{epoch+1}.pth\")\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        for batch, label in tqdm(dataloader, position=0, leave=True):\n",
    "            for key in batch:\n",
    "                batch[key] = batch[key].to(device, dtype=torch.long)\n",
    "\n",
    "            label['action'] = label['action'].to(device, dtype=torch.long)\n",
    "            label['attributes'] = label['attributes'].to(device, dtype=torch.float)\n",
    "            with torch.no_grad():\n",
    "                action_logits, action_pred, attributes_logits, attributes_pred = model(batch, label, predict=False)\n",
    "\n",
    "            # action, attributes  metrics loss\n",
    "            loss_action = loss_function_action(action_logits.view(-1, Action.length()), label['action'].view(-1))\n",
    "            # if you wish to use a weighted CrossEntropy loss, comment the line above and uncomment the line below\n",
    "            # loss_action = loss_function_action(action_logits, label['action'])\n",
    "            total_loss_action += loss_action.item()\n",
    "            #:\n",
    "            loss_attrs = loss_function_attributes(attributes_logits.view(-1, Attribute.length()), label['attributes'].view(-1,Attribute.length()))\n",
    "            total_loss_attrs += loss_attrs.item()\n",
    "            counter_loss += 1\n",
    "        # save results\n",
    "        loss_action = total_loss_action/counter_loss\n",
    "        loss_attributes = total_loss_attrs/counter_loss\n",
    "        loss_act_array.append(loss_action)\n",
    "        loss_attrs_array.append(loss_attributes)\n",
    "        print(f\"Epoch {epoch + 1}:\\nAction loss: {loss_action} | Attributes loss: {loss_attributes}\")\n",
    "    # append vector in list for split \n",
    "    losses_act_array.append(loss_act_array)\n",
    "    losses_attrs_array.append(loss_attrs_array)\n",
    "    #\n",
    "    loss_action = total_loss_action/counter_loss\n",
    "    print(f'Evaluate {split} Loss action: {loss_action}')\n",
    "    #\n",
    "    loss_attributes = total_loss_attrs/counter_loss\n",
    "    print(f'Evaluate {split} Loss attributes: {loss_attributes}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F02JdPwlkM5g"
   },
   "source": [
    "# RESULT PLOTS\n",
    "\n",
    "Use these plots to check for the overfitting point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 606
    },
    "id": "GwlO6UJDkMJp",
    "outputId": "dc5e65a1-1ecf-4360-8d19-1bb866b38e06"
   },
   "outputs": [],
   "source": [
    "x = np.arange(1, MAX_EPOCHS + 1, 1)\n",
    "x_minor = np.arange(1, MAX_EPOCHS + 1, 0.5)\n",
    "\n",
    "def make_plot(y_train, y_test, y_dev, title: str, ylabel: str, fig_path: str):\n",
    "    fig, ax = plt.subplots(figsize=(7.5, 7.5))\n",
    "    plt.plot(x, y_train, label=f'TRAIN Set')\n",
    "    plt.plot(x, y_test, label=f'TEST set', linestyle=\"dashed\")\n",
    "    plt.plot(x, y_dev, label=f'DEV set', linestyle=\"dotted\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.legend()\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticks(x_minor, minor=True)\n",
    "    ax.grid(which='minor', alpha=0.2)\n",
    "    ax.grid(which='major', alpha=0.5)\n",
    "    plt.savefig(fig_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "hyper_params = \" - \".join([\n",
    "    f\"lr={LEARNING_RATE}\",\n",
    "    f\"epochs={MAX_EPOCHS}\",\n",
    "    f\"tr_btch_sz={TRAIN_BATCH_SIZE}\",\n",
    "    f\"tst_btch_sz={TEST_BATCH_SIZE}\",\n",
    "    f\"hdn_state={FEATURES}\",\n",
    "    f\"act_drop={ACTION_DROPOUT}\",\n",
    "    f\"attr_drop={ATTRIBUTES_DROPOUT}\",\n",
    "    f\"disc_attrs={DISCARD_ATTRIBUTES_BELOW_COUNT}\",\n",
    "    f\"history={HISTORY}\",\n",
    "])\n",
    "    \n",
    "# Action Loss\n",
    "print(\"ACTION LOSS PLOTS\")\n",
    "make_plot(loss_act_array_tr, \n",
    "          losses_act_array[0], \n",
    "          losses_act_array[1],\n",
    "          f\"CrossEntropyLoss ACTION {hyper_params}\",\n",
    "          \"CrossEntropyLoss\",\n",
    "          f\"{PROJECT_DIR}RESULTS/losses_action{HISTORY}.png\")\n",
    "\n",
    "# Attributes Loss\n",
    "print(f\"ATTRIBUTES LOSS PLOTS\")\n",
    "make_plot(loss_attrs_array_tr,\n",
    "          losses_attrs_array[0],\n",
    "          losses_attrs_array[1],\n",
    "          f\"BCEWithLogitsLoss ATTRIBUTES {hyper_params}\",\n",
    "          \"BCEWithLogitsLoss\",\n",
    "          f\"{PROJECT_DIR}RESULTS/losses_attributes{HISTORY}.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iepG6bu3l4qF"
   },
   "source": [
    "# GENERATE OUTPUT \n",
    "\n",
    "In the following cell, we generate the actual output of the best checkpoint of the model (to choose by looking at the graphs above, `MAX_EPOCHS` by default).  \n",
    "If we observe an intersection between the TRAIN and DEV lines in the actions or attributes losses graphs above, we should pick the highest epoch number after that point where the DEV loss is approximately the same as it was at the intersection point, to allow for the other loss (typically, the one of the attributes) to decrease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "smfFv3k7GcOo"
   },
   "outputs": [],
   "source": [
    "def save_output_model(num_epoch, dataloader, split):\n",
    "    print(f\"Creating output of model in RESULTS folder...\")\n",
    "    model = torch.load(f\"{PROJECT_DIR}MODELS/model_epoch{num_epoch}.pth\")\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    dialog_ids = []\n",
    "    results_dials = []\n",
    "    output = []\n",
    "    cont=0\n",
    "    for batch, label in tqdm(dataloader, position=0, leave=True):\n",
    "        for key in batch:\n",
    "            batch[key] = batch[key].to(device, dtype=torch.long)\n",
    "        label['action'] = label['action'].to(device, dtype=torch.long)\n",
    "        label['attributes'] = label['attributes'].to(device, dtype=torch.float)\n",
    "        with torch.no_grad():\n",
    "          action_logits, action_pred, attributes_logits, attributes_pred = model(batch, label, predict=True)\n",
    "        i = 0\n",
    "        for dialog_id in batch[\"dialog_id\"]:\n",
    "          #save info for dials turns\n",
    "          attributes = []\n",
    "          j = 0\n",
    "          for index in range(len(attributes_pred[i])):\n",
    "            if attributes_pred[i][index] == 1:\n",
    "              attributes.append(Attribute.from_number(index))\n",
    "          result_turn = {\n",
    "              \"turn_id\": batch[\"turn_idx\"][i].item(),\n",
    "              \"action\": Action.from_number(action_pred[i]),\n",
    "              \"action_log_prob\": {\n",
    "                  Action.from_number(0):action_logits[i][0].item(),\n",
    "                  Action.from_number(1):action_logits[i][1].item(),\n",
    "                  Action.from_number(2):action_logits[i][2].item(),\n",
    "                  Action.from_number(3):action_logits[i][3].item(),\n",
    "                  Action.from_number(4):action_logits[i][4].item()\n",
    "              },\n",
    "              \"attributes\": attributes\n",
    "          }\n",
    "          if dialog_id not in dialog_ids:\n",
    "              dialog_ids.append(dialog_id.item())\n",
    "              vect = [result_turn]\n",
    "              results_dials.append(vect)\n",
    "          else:\n",
    "              results_dials[dialog_ids.index(dialog_id)].append(result_turn)\n",
    "          i += 1\n",
    "    i = 0\n",
    "\n",
    "    for dialog_id in dialog_ids:\n",
    "      predictions = []\n",
    "      for result in results_dials[i]:\n",
    "          predictions.append({\n",
    "              \"action\": result[\"action\"],\n",
    "              \"action_log_prob\": result[\"action_log_prob\"],\n",
    "              \"attributes\": {\n",
    "                  \"attributes\": result[\"attributes\"]\n",
    "              }, \n",
    "              \"turn_id\": result[\"turn_id\"]\n",
    "          })\n",
    "      output.append({\n",
    "        \"dialog_id\": dialog_id,\n",
    "        \"predictions\": predictions\n",
    "      })\n",
    "      i = i+1\n",
    "    # training results\n",
    "    print(f\"Savings output of model in RESULTS folder\")\n",
    "    with open(f\"{PROJECT_DIR}RESULTS/output_{split}{HISTORY}.json\", \"w\") as f:\n",
    "        json.dump(output, f)\n",
    "\n",
    "SPLITS_FILE = [TEST_FILE]\n",
    "# uncomment the following line if you want to generate the output for all the dataset splits\n",
    "# keep in mind it takes a very long time, in the hours order of magnitude\n",
    "# SPLITS_FILE = [TRAIN_FILE, TEST_FILE, DEV_FILE]\n",
    "\n",
    "for file in SPLITS_FILE:\n",
    "    if \"train\" in file:\n",
    "        split = \"train\"\n",
    "    elif \"devtest\" in file:\n",
    "        split = \"devtest\"\n",
    "    else:\n",
    "        split = \"dev\"\n",
    "\n",
    "    dataset = Dataset(file)\n",
    "    params = {\n",
    "        'shuffle': True,\n",
    "        'batch_size': TRAIN_BATCH_SIZE if split == \"train\" else TEST_BATCH_SIZE\n",
    "    }\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, **params)\n",
    "    print(f\"Generate output of model for {split} dataset with {len(dataset)} entries.\")\n",
    "    save_output_model(MAX_EPOCHS, dataloader, split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "biI6nnz6Rc7f"
   },
   "source": [
    "# EVALUATE ACCURACY AND PERPLEXITY OF OUTPUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c0mZ1iIzJPf9"
   },
   "outputs": [],
   "source": [
    "\"\"\"Script evaluates action prediction along with attributes.\n",
    "Author(s): Satwik Kottur\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "IGNORE_ATTRIBUTES = [\n",
    "    \"minPrice\",\n",
    "    \"maxPrice\",\n",
    "    \"furniture_id\",\n",
    "    \"material\",\n",
    "    \"decorStyle\",\n",
    "    \"intendedRoom\",\n",
    "    \"raw_matches\",\n",
    "    \"focus\",  # fashion\n",
    "]\n",
    "\n",
    "def evaluate_action_prediction(\n",
    "    gt_actions,\n",
    "    model_actions,\n",
    "    single_round_eval=False,\n",
    "    compute_std_err=False,\n",
    "    record_instance_results=None,\n",
    "):\n",
    "    \"\"\"Evaluates action prediction using the raw data and model predictions.\n",
    "    Args:\n",
    "        gt_actions: Ground truth actions + action attributes\n",
    "        model_actions: Actions + attributes predicted by the model\n",
    "        single_round_eval: Evaluate only for the last turn\n",
    "        compute_std_err: Computes standard error for the metrics\n",
    "        record_instance_results: Record the result per instance\n",
    "    \"\"\"\n",
    "    gt_actions_pool = {ii[\"dialog_id\"]: ii for ii in gt_actions}\n",
    "    matches = {\"action\": [], \"attributes\": [], \"perplexity\": []}\n",
    "    confusion_dict = collections.defaultdict(list)\n",
    "    for model_datum in model_actions:\n",
    "        dialog_id = model_datum[\"dialog_id\"]\n",
    "        num_gt_rounds = len(gt_actions_pool[dialog_id][\"actions\"])\n",
    "        for round_datum in model_datum[\"predictions\"]:\n",
    "            round_id = round_datum[\"turn_id\"]\n",
    "            # Skip if single_round_eval and this is not the last round.\n",
    "            if single_round_eval and round_id != num_gt_rounds - 1:\n",
    "                continue\n",
    "\n",
    "            gt_datum = gt_actions_pool[dialog_id][\"actions\"][round_id]\n",
    "            action_match = gt_datum[\"action\"] == round_datum[\"action\"]\n",
    "            # Record matches and confusion.\n",
    "            matches[\"action\"].append(action_match)\n",
    "            matches[\"perplexity\"].append(\n",
    "                round_datum[\"action_log_prob\"][gt_datum[\"action\"]]\n",
    "            )\n",
    "            confusion_dict[gt_datum[\"action\"]].append(round_datum[\"action\"])\n",
    "\n",
    "            # Add the result to datum and save it back.\n",
    "            if record_instance_results:\n",
    "                round_datum[\"action_result\"] = action_match\n",
    "                round_datum[\"gt_action\"] = gt_datum[\"action\"]\n",
    "\n",
    "            # Get supervision for action attributes.\n",
    "            supervision = gt_datum[\"action_supervision\"]\n",
    "            if supervision is not None and \"args\" in supervision:\n",
    "                supervision = supervision[\"args\"]\n",
    "            if supervision is None:\n",
    "                continue\n",
    "            #Case 1: Action mismatch -- record False for all attributes.\n",
    "            if not action_match:\n",
    "                for key in supervision.keys():\n",
    "                    if key in IGNORE_ATTRIBUTES:\n",
    "                        continue\n",
    "                    matches[\"attributes\"].append(False)\n",
    "            # Case 2: Action matches -- use model predictions for attributes.\n",
    "            else:\n",
    "                for key in supervision.keys():\n",
    "                    if key in IGNORE_ATTRIBUTES:\n",
    "                        continue\n",
    "                    gt_key_vals = supervision[key]\n",
    "                    model_key_vals = round_datum[\"attributes\"][key]\n",
    "\n",
    "                    if not len(gt_key_vals):\n",
    "                        continue\n",
    "                    # For fashion, this is a list -- multi label prediction.\n",
    "                    if isinstance(gt_key_vals, list):\n",
    "                        assert isinstance(\n",
    "                            model_key_vals, list\n",
    "                        ), \"Model should also predict a list for attributes\"\n",
    "                        recall = np.mean([(ii in model_key_vals) for ii in gt_key_vals])\n",
    "                        if len(model_key_vals):\n",
    "                            precision = np.mean(\n",
    "                                [(ii in gt_key_vals) for ii in model_key_vals]\n",
    "                            )\n",
    "                        else:\n",
    "                            precision = 0.0\n",
    "                        f1_score = (2 * recall * precision) / (\n",
    "                            recall + precision + 1e-6\n",
    "                        )\n",
    "                        matches[\"attributes\"].append(f1_score)\n",
    "                    else:\n",
    "                        # For furniture, this is a string -- single label prediction.\n",
    "                        matches[\"attributes\"].append(gt_key_vals == model_key_vals)\n",
    "\n",
    "    print(\"#Instances evaluated API: {}\".format(len(matches[\"action\"])))\n",
    "    # Record and save per instance results.\n",
    "    if record_instance_results:\n",
    "        print(\"Saving per instance result: {}\".format(record_instance_results))\n",
    "        with open(record_instance_results, \"w\") as file_id:\n",
    "            json.dump(model_actions, file_id)\n",
    "\n",
    "    # Compute the confusion matrix.\n",
    "    all_actions = sorted(\n",
    "        set(confusion_dict.keys()).union(\n",
    "            {jj for ii in confusion_dict.values() for jj in ii}\n",
    "        )\n",
    "    )\n",
    "    matrix = np.zeros((len(all_actions), len(all_actions)))\n",
    "    for index, action in enumerate(all_actions):\n",
    "        labels, counts = np.unique(confusion_dict[action], return_counts=True)\n",
    "        for label, count in zip(labels, counts):\n",
    "            matrix[all_actions.index(label), index] += count\n",
    "    metrics = {\n",
    "        \"action_accuracy\": np.mean(matches[\"action\"]),\n",
    "        \"action_perplexity\": np.exp(-1 * np.mean(matches[\"perplexity\"])),\n",
    "        \"attribute_accuracy\": np.mean(matches[\"attributes\"]),\n",
    "        \"confusion_matrix\": matrix,\n",
    "    }\n",
    "    if compute_std_err:\n",
    "        metrics_std_err = {\n",
    "            \"action_accuracy\": (\n",
    "                np.std(matches[\"action\"]) / np.sqrt(len(matches[\"action\"]))\n",
    "            ),\n",
    "            \"action_perplexity\": (\n",
    "                (\n",
    "                    np.exp(-1 * np.std(matches[\"perplexity\"]))\n",
    "                    / np.sqrt(len(matches[\"perplexity\"]))\n",
    "                )\n",
    "            ),\n",
    "            \"attribute_accuracy\": (\n",
    "                np.std(matches[\"attributes\"]) / np.sqrt(len(matches[\"attributes\"]))\n",
    "            ),\n",
    "        }\n",
    "        return metrics, metrics_std_err\n",
    "    else:\n",
    "        return metrics\n",
    "    \n",
    "\n",
    "for file in SPLITS_FILE:\n",
    "    if \"train\" in file:\n",
    "        split = \"train\"\n",
    "    elif \"devtest\" in file:\n",
    "        split = \"devtest\"\n",
    "    else:\n",
    "        split = \"dev\"\n",
    "    \n",
    "    if HISTORY != 0:\n",
    "        HISTORY_PAD = HISTORY\n",
    "        \n",
    "    print(\"Reading: {}\".format(f\"{DATA_DIR}fashion_{split}_dials_api_calls.json\"))\n",
    "    with open(f\"{DATA_DIR}fashion_{split}_dials_api_calls.json\", \"r\") as file_id:\n",
    "        gt_actions = json.load(file_id)\n",
    "    \n",
    "    print(\"Reading: {}\".format(f\"{PROJECT_DIR}RESULTS/output_{split}{HISTORY_PAD}.json\"))\n",
    "    with open(f\"{PROJECT_DIR}RESULTS/output_{split}{HISTORY_PAD}.json\", \"r\") as file_id:\n",
    "        model_actions = json.load(file_id)\n",
    "    \n",
    "    action_metrics = evaluate_action_prediction(\n",
    "        gt_actions,\n",
    "        model_actions,\n",
    "    )\n",
    "    # print(action_metrics)\n",
    "    \n",
    "    if split == \"devtest\":\n",
    "        results_json = f\"{PROJECT_DIR}RESULTS/metrics.json\"\n",
    "        print(f\"Saving metrics result as {results_json}\")\n",
    "        metrics = {\n",
    "            \"hyperparameters\":{\n",
    "                \"learning_rate\": LEARNING_RATE,\n",
    "                \"discard_attributes_below_count\": DISCARD_ATTRIBUTES_BELOW_COUNT,\n",
    "                \"features\": FEATURES,\n",
    "                \"action_dropout\": ACTION_DROPOUT,\n",
    "                \"attributes_dropout\": ATTRIBUTES_DROPOUT,\n",
    "                \"max_epochs\": MAX_EPOCHS,\n",
    "                \"train_batch_size\": TRAIN_BATCH_SIZE,\n",
    "                \"test_batch_size\": TEST_BATCH_SIZE,\n",
    "                \"history\": HISTORY,\n",
    "            },\n",
    "            \"action_accuracy\": action_metrics['action_accuracy'].astype(float),\n",
    "            \"action_perplexity\": action_metrics['action_perplexity'].astype(float),\n",
    "            \"attribute_accuracy\":action_metrics['attribute_accuracy'].astype(float),\n",
    "        }\n",
    "        with open(results_json, \"w\") as f:\n",
    "            json.dump(metrics, f)\n",
    "        \n",
    "    plt.rcParams[\"figure.autolayout\"] = True\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    data = [[action_metrics['action_accuracy'], action_metrics['action_perplexity'], action_metrics['attribute_accuracy']]]\n",
    "    column_labels=[\"Action Accuracy\", \"Action Perplexity\", \"Attribute Accuracy\"]\n",
    "    ax.axis('tight')\n",
    "    ax.axis('off')\n",
    "    table = ax.table(cellText=data, colLabels=column_labels, loc=\"center\")\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(24)\n",
    "    table.scale(5, 5)\n",
    "    plt.savefig(f\"{PROJECT_DIR}RESULTS/metrics_{split}{HISTORY}.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "         \n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    labels = [''] + [Action.from_number(a.value) for a in Action]\n",
    "    mat = ax.matshow(action_metrics['confusion_matrix'], alpha=0.5)\n",
    "    for i in range(action_metrics['confusion_matrix'].shape[0]):\n",
    "        for j in range(action_metrics['confusion_matrix'].shape[1]):\n",
    "            ax.text(x=j, y=i, s=action_metrics['confusion_matrix'][i, j], va='center', ha='center', size='xx-large')\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.tick_params('x', labelrotation=45)\n",
    "    ax.xaxis.set_ticks_position(\"bottom\")\n",
    "    ax.set_yticklabels(labels)\n",
    "    plt.colorbar(mat)\n",
    "    plt.xlabel('Action Predictions', fontsize=18)\n",
    "    plt.ylabel('Action Ground Truth', fontsize=18)\n",
    "    plt.title('Actions Confusion Matrix', fontsize=22)\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(f\"{PROJECT_DIR}RESULTS/metrics_actions_conf_mat_{split}{HISTORY}.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "AIML_project_with_more_batches_bertbase.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "031bf5191a61439cb0e61cff553e7baa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0b5155bf72bb4e9b9353b537d16b8da1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1fb808764af44f029c1f1dce96d304f6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2624feef679145caa2dd8a6add7ebbaf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9c741453c05f4d7baff52189a8e23b9b",
       "IPY_MODEL_88c826d18c1b4b148ad7f860502a0387",
       "IPY_MODEL_b7d6332b2ed94d6aa4c4865df0007459"
      ],
      "layout": "IPY_MODEL_57e92482a66a4f6c896999e78945c715"
     }
    },
    "286b546fecfc401dad698815a6ae792c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_320aeb208cf74263bd6a32e82cab7b62",
      "placeholder": "​",
      "style": "IPY_MODEL_aef37d1229c64f91a56b0dea7a1b03e8",
      "value": " 440M/440M [00:13&lt;00:00, 34.3MB/s]"
     }
    },
    "29ef9d781eb34502b11d666c2c5988ee": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2a2df1587d824a13998c6d31e949f685": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "320aeb208cf74263bd6a32e82cab7b62": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "57e92482a66a4f6c896999e78945c715": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6863eb04e9ff4018b4eba17c68776a6b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8896645e63b247b7916fdca9000b5fff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "88c826d18c1b4b148ad7f860502a0387": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_29ef9d781eb34502b11d666c2c5988ee",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2a2df1587d824a13998c6d31e949f685",
      "value": 570
     }
    },
    "9c741453c05f4d7baff52189a8e23b9b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_af4b6754ed0f478981861fbc860af8c0",
      "placeholder": "​",
      "style": "IPY_MODEL_a2d9ca91e34a4c91914d0b804a1c63bf",
      "value": "Downloading: 100%"
     }
    },
    "a2d9ca91e34a4c91914d0b804a1c63bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "aef37d1229c64f91a56b0dea7a1b03e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "af4b6754ed0f478981861fbc860af8c0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b7d6332b2ed94d6aa4c4865df0007459": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1fb808764af44f029c1f1dce96d304f6",
      "placeholder": "​",
      "style": "IPY_MODEL_6863eb04e9ff4018b4eba17c68776a6b",
      "value": " 570/570 [00:00&lt;00:00, 13.0kB/s]"
     }
    },
    "ceb339d318c34c69a9db64cdb1b4b4ea": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dd6602d9fbf844cba23074cc26e12c4e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_031bf5191a61439cb0e61cff553e7baa",
      "max": 440473133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8896645e63b247b7916fdca9000b5fff",
      "value": 440473133
     }
    },
    "e9960e30c15c44a99e400fd040e4f06a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f1571617dfce49538fc2fb6364365bcf",
      "placeholder": "​",
      "style": "IPY_MODEL_0b5155bf72bb4e9b9353b537d16b8da1",
      "value": "Downloading: 100%"
     }
    },
    "f1571617dfce49538fc2fb6364365bcf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "faff48e5ef5c445aa8d793551d6594ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e9960e30c15c44a99e400fd040e4f06a",
       "IPY_MODEL_dd6602d9fbf844cba23074cc26e12c4e",
       "IPY_MODEL_286b546fecfc401dad698815a6ae792c"
      ],
      "layout": "IPY_MODEL_ceb339d318c34c69a9db64cdb1b4b4ea"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
